# Cargar las librerías listadas e instalarlas en caso de ser necesario
p_load(tidyverse, # Manipular dataframes
stringi, # Manipular cadenas de texto
rio, # Importar datos fácilmente
sf, # Leer/escribir/manipular datos espaciales
tidymodels, # entrenamiento de modelos
spatialsample, # Muestreo espacial para modelos de aprendizaje automático
rsample, # Resamplear los datos
dplyr,
parsnip, # elastic net
dials, # elastic net tunning
recipes, # Recetas
workflows,# Crear worklows RN
metrics,# Evaluación de metricas para Ml
tidymodels,#modelos
randomforest,
ranger,
rlang,
tune,
adabag)
# Cargar paquetes ---------------------------------------------------------
library(pacman)
# Cargar las librerías listadas e instalarlas en caso de ser necesario
p_load(tidyverse, # Manipular dataframes
stringi, # Manipular cadenas de texto
rio, # Importar datos fácilmente
sf, # Leer/escribir/manipular datos espaciales
tidymodels, # entrenamiento de modelos
spatialsample, # Muestreo espacial para modelos de aprendizaje automático
rsample, # Resamplear los datos
dplyr,
parsnip, # elastic net
dials, # elastic net tunning
recipes, # Recetas
workflows,# Crear worklows RN
metrics,# Evaluación de metricas para Ml
tidymodels,#modelos
randomforest,
ranger,
rlang,
tune,
adabag)
load("temporal.RData")
# Cargar paquetes ---------------------------------------------------------
library(pacman)
install.packages("rstudioapi")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
load("temporal.RData")
# RANDOM FOREST-----------------------------------------------------------------
vars<- c("price", "year", "surface_imputado", "rooms",
"bedrooms", "bathrooms", "property_type",
"cocina_lujo", "cocina_estandar", "parqueadero", "terraza",
"sala_comedor", "patio_lavanderia", "walkin_closet", "estudio",
"closet", "saloncomunal_recepcion", "seguridad", "piso",
"lujos", "remodelado",  "distancia_commercial",
"distancia_bank", "distancia_bus_station",
"distancia_cafe",  "distancia_college",
"distancia_hospital", "distancia_marketplace")
RF_data  <- df %>% filter(grupo == "train") %>%  select(all_of(vars))
# ADABOOST M1 -----------------------------------------------------------------
AdaBase <- df %>% filter(grupo == "train") %>% select(all_of(vars))
rec_ada <- recipe(price ~ ., data = AdaBase) %>%
step_unknown(all_nominal_predictors()) %>%
step_impute_mean(all_numeric_predictors()) %>%
step_novel(all_nominal_predictors()) %>%
step_zv(all_predictors())
prepped_ada <- prep(rec_ada, training = AdaBase)
AdaBase <- bake(prepped_ada, new_data = AdaBase)
set.seed(123)
split_ada <- initial_split(AdaBase, prop = 0.8)
Ada_train <- training(split_ada)
Ada_test <- testing(split_ada)
# 1. Selección de variables y filtrado de datos
vars2 <- c("price", "surface_imputado", "bathrooms", "rooms", "bedrooms",
"estudio", "parqueadero", "distancia_college")
AdaBase <- df %>% filter(grupo == "train") %>% select(all_of(vars2))
# 2. Receta de preprocesamiento
rec_ada <- recipe(price ~ ., data = AdaBase) %>%
step_unknown(all_nominal_predictors()) %>%
step_impute_mean(all_numeric_predictors()) %>%
step_novel(all_nominal_predictors()) %>%
step_zv(all_predictors())
prepped_ada <- prep(rec_ada, training = AdaBase)
AdaBase <- bake(prepped_ada, new_data = AdaBase)
# 3. División en entrenamiento y prueba
set.seed(123)
split_ada <- initial_split(AdaBase, prop = 0.8)
Ada_train <- training(split_ada)
Ada_test <- testing(split_ada)
# 4. Entrenar el modelo AdaBoostM1
set.seed(123)
ada_fit <- boosting(
formula = price ~ surface_imputado + bathrooms + rooms + bedrooms + estudio + parqueadero + distancia_college,
data = Ada_train,
boos = TRUE,
mfinal = 100  # Número de iteraciones
)
nrow(AdaBase)
print(cv_folds)
cv_folds <- vfold_cv(AdaBase, v = 5)
# 4. Entrenar el modelo AdaBoostM1
set.seed(123)
ada_fit <- boosting(
formula = price ~ surface_imputado + bathrooms + rooms + bedrooms + estudio + parqueadero + distancia_college,
data = Ada_train,
boos = TRUE,
mfinal = 100  # Número de iteraciones
)
cv_folds <- vfold_cv(AdaBase, v = 5)
print(dim(AdaBase))  # Muestra el número de filas y columnas
print(cv_folds)
# 4. Entrenar el modelo AdaBoostM1
set.seed(123)
ada_fit <- boosting(
formula = price ~ surface_imputado + bathrooms + rooms + bedrooms + estudio + parqueadero + distancia_college,
data = Ada_train,
boos = TRUE,
mfinal = 100
)
print(dim(Ada_train))  # Muestra el número de filas y columnas
print(str(Ada_train))  # Muestra la estructura del conjunto de datos
print(class(Ada_train$price))
sum(is.na(Ada_train))
summary(Ada_train)
# 2. Receta de preprocesamiento
rec_ada <- recipe(price ~ ., data = AdaBase) %>%
step_string2factor(all_nominal_predictors()) %>%
step_unknown(all_nominal_predictors()) %>%
step_novel(all_nominal_predictors()) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
step_impute_mean(all_numeric_predictors()) %>%
step_zv(all_predictors())
prepped_ada <- prep(rec_ada, training = AdaBase)
# 2. Receta de preprocesamiento
rec_ada <- recipe(price ~ ., data = AdaBase) %>%
step_unknown(all_nominal_predictors()) %>%
step_impute_mean(all_numeric_predictors()) %>%
step_novel(all_nominal_predictors()) %>%
step_zv(all_predictors())
prepped_ada <- prep(rec_ada, training = AdaBase)
AdaBase <- bake(prepped_ada, new_data = AdaBase)
AdaBase <- df %>% filter(grupo == "train") %>% select(all_of(vars2))
# 2. Receta de preprocesamiento
rec_ada <- recipe(price ~ ., data = AdaBase) %>%
step_unknown(all_nominal_predictors()) %>%
step_impute_mean(all_numeric_predictors()) %>%
step_novel(all_nominal_predictors()) %>%
step_zv(all_predictors())
prepped_ada <- prep(rec_ada, training = AdaBase)
AdaBase <- bake(prepped_ada, new_data = AdaBase)
# 3. División en entrenamiento y prueba
set.seed(123)
split_ada <- initial_split(AdaBase, prop = 0.8)
Ada_train <- training(split_ada)
Ada_test <- testing(split_ada)
print(dim(Ada_train))  # Muestra el número de filas y columnas
ada_fit <- boosting(
formula = price ~ surface_imputado + bathrooms + rooms + bedrooms + estudio + parqueadero + distancia_college,
data = Ada_train,
boos = TRUE,
mfinal = 100
)
sapply(Ada_train, function(x) length(unique(x)))
ada_fit <- boosting(
formula = price ~ surface_imputado + bathrooms + bedrooms  + distancia_college,
data = Ada_train,
boos = TRUE,
mfinal = 100
)
sapply(Ada_train, function(x) length(unique(x)))
ada_fit <- boosting(
formula = price ~ surface_imputado + bathrooms + bedrooms ,
data = Ada_train,
boos = TRUE,
mfinal = 100
)
# 4. Entrenar el modelo AdaBoostM1
set.seed(123)
ada_fit <- boosting(
formula = price ~ surface_imputado + bathrooms + bedrooms,
data = Ada_train,
boos = TRUE,
mfinal = 100
)
